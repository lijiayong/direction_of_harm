{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUGpQn1+GUiI0R8hGQLiof"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is for inference using a fine-tuned Open AI gpt-4o-mini model."
      ],
      "metadata": {
        "id": "sUu51VAX-zSZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMtGtwhROSfK"
      },
      "outputs": [],
      "source": [
        "!pip3 install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CUFTbR5kO04o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "1IOnKB0mO23m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CONFIG:\n",
        "    model = 'ft:gpt-4o-mini-2024-07-18:personal::A7TQ6aWo'\n",
        "    lines_per_task = 1"
      ],
      "metadata": {
        "id": "0SLtXJQn7f-w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PATHS:\n",
        "    save = '/content/drive/MyDrive'\n",
        "    few_shot = f'{save}/few_shot_labeled.tsv'\n",
        "    train = f'{save}/ft-train_labeled.tsv'\n",
        "    valid = f'{save}/ft-valid_labeled.tsv'\n",
        "    sw = f'{save}/subreddit_SuicideWatch_900_v2_trimmed.tsv'\n",
        "    ar = f'{save}/subreddit_abusiverelationships_900_v2_trimmed.tsv'\n",
        "    arc = f'{save}/subreddit_abusiverelationships_600_v2_comments_trimmed.tsv'\n",
        "    toxic = f'{save}/jigsaw_toxic_2019_threshold_0.9.tsv'"
      ],
      "metadata": {
        "id": "Y3loBB-R5hSR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_df = pd.read_csv(PATHS.few_shot, sep='\\t', dtype={'id': 'string'})\n",
        "train_df = pd.read_csv(PATHS.train, sep='\\t', dtype={'id': 'string'})\n",
        "valid_df = pd.read_csv(PATHS.valid, sep='\\t', dtype={'id': 'string'})\n",
        "all_train_df = pd.concat([train_df, valid_df])\n",
        "sw_df = pd.read_csv(PATHS.sw, sep='\\t', dtype={'id': 'string'})\n",
        "ar_df = pd.read_csv(PATHS.ar, sep='\\t', dtype={'id': 'string'})\n",
        "arc_df = pd.read_csv(PATHS.arc, sep='\\t', dtype={'id': 'string'})\n",
        "toxic_df = pd.read_csv(PATHS.toxic_v2, sep='\\t', dtype={'id': 'string'})"
      ],
      "metadata": {
        "id": "Iy3_Cbb25a5G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "iVJIrnX-4000"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Response Format"
      ],
      "metadata": {
        "id": "Ly_HMu9_Pnuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_format = {\n",
        "    \"type\": \"json_schema\",\n",
        "    \"json_schema\": {\n",
        "        \"strict\": True,\n",
        "        \"name\": \"harmlabels\",\n",
        "        \"schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"id\": {\n",
        "                    \"type\": \"string\"\n",
        "                },\n",
        "                \"self_harm\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"enum\": [0, 1]\n",
        "                },\n",
        "                \"harming_others\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"enum\": [0, 1]\n",
        "                },\n",
        "                \"harmed_by_others\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"enum\": [0, 1]\n",
        "                },\n",
        "                \"reference_to_harm\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"enum\": [0, 1]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"id\", \"self_harm\", \"harming_others\", \"harmed_by_others\", \"reference_to_harm\"\n",
        "            ],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "20kai_hlhF4L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Prompt"
      ],
      "metadata": {
        "id": "DiRJmz6fFClR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"You are a data labeler. The targets are 'self_harm', 'harming_others', 'harmed_by_others', and 'reference_to_harm', label each target as 0 or 1.\n",
        "1. 'self_harm': harm directed from me to me\n",
        "2. 'harming_others': harm directed from me to other people\n",
        "3. 'harmed_by_others': harm directed from other people to me\n",
        "4. 'reference_to_harm': harm directed from other people to other people\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tRGI1fGMC8xF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action = \"\"\"Label the following texts. Return 'id', 'self_harm', 'harming_others', 'harmed_by_others', and 'reference_to_harm'. 'id' is the same as input.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9VnanPuiDF5D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['self_harm', 'harming_others', 'harmed_by_others','reference_to_harm']"
      ],
      "metadata": {
        "id": "G6DtczG-qBkR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Inference"
      ],
      "metadata": {
        "id": "UV0yi8cl6Tjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(filename):\n",
        "    split = []\n",
        "    df = pd.read_csv(filename, sep='\\t')\n",
        "    for i in range(0, len(df), CONFIG.lines_per_task):\n",
        "        text = df.iloc[i: i+CONFIG.lines_per_task].to_csv(sep='\\t', index=False, header=False)\n",
        "        split.append((i//CONFIG.lines_per_task, text))\n",
        "    return split"
      ],
      "metadata": {
        "id": "OT-mSQV7Cm91"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_task(index, text, model):\n",
        "    task = {\n",
        "        \"custom_id\": f\"task_{index}\",\n",
        "        \"method\": \"POST\",\n",
        "        \"url\": \"/v1/chat/completions\",\n",
        "        \"body\": {\n",
        "            \"model\": model,\n",
        "            \"temperature\": 0,\n",
        "            \"max_tokens\": 256,\n",
        "            \"response_format\": response_format,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": instruction,\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": ''.join([action, text]),\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "    return task"
      ],
      "metadata": {
        "id": "eTiszYCI5i-v"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inference_jsonl(input, output, model):\n",
        "    split = split_text(input)\n",
        "    # write jsonl\n",
        "    with open(output, 'w') as f:\n",
        "        for index, text in split:\n",
        "            task = get_task(index, text, model)\n",
        "            f.write(json.dumps(task) + '\\n')"
      ],
      "metadata": {
        "id": "dYhXPq0-Vig_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_batch(jsonl_file):\n",
        "    # upload jsonl\n",
        "    batch_file = client.files.create(\n",
        "        file=open(jsonl_file, 'rb'),\n",
        "        purpose=\"batch\",\n",
        "    )\n",
        "    # submit batch job\n",
        "    batch_job = client.batches.create(\n",
        "        input_file_id=batch_file.id,\n",
        "        endpoint=\"/v1/chat/completions\",\n",
        "        completion_window=\"24h\",\n",
        "    )\n",
        "    return batch_job"
      ],
      "metadata": {
        "id": "_9ucyXQ5-wTI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit suicide watch inference"
      ],
      "metadata": {
        "id": "TZNw033ufO_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_jsonl = f'{PATHS.save}/sw_inference.jsonl'\n",
        "make_inference_jsonl(PATHS.sw, inference_jsonl, CONFIG.model)"
      ],
      "metadata": {
        "id": "kl6a7JaUcfKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = submit_batch(inference_jsonl)"
      ],
      "metadata": {
        "id": "uHjZMMQojGzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = client.batches.retrieve(batch_job.id)\n",
        "print(batch_job)"
      ],
      "metadata": {
        "id": "S5pB4otQjaSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_file_id = batch_job.output_file_id\n",
        "result = client.files.content(result_file_id).content\n",
        "sw_predicted_jsonl = f'{PATHS.save}/sw_predicted.jsonl'\n",
        "with open(sw_predicted_jsonl, 'wb') as f:\n",
        "    f.write(result)"
      ],
      "metadata": {
        "id": "avaA490dlLvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit abusive relationship inference"
      ],
      "metadata": {
        "id": "17InMbHEfYWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_jsonl = f'{PATHS.save}/ar_inference.jsonl'\n",
        "make_inference_jsonl(PATHS.ar, inference_jsonl, CONFIG.model)"
      ],
      "metadata": {
        "id": "WiiIP4YlfBZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = submit_batch(inference_jsonl)"
      ],
      "metadata": {
        "id": "JPR5wiExfBZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = client.batches.retrieve(batch_job.id)\n",
        "print(batch_job)"
      ],
      "metadata": {
        "id": "PRc6PSVtfBZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_file_id = batch_job.output_file_id\n",
        "result = client.files.content(result_file_id).content\n",
        "ar_predicted_jsonl = f'{PATHS.save}/ar_predicted.jsonl'\n",
        "with open(ar_predicted_jsonl, 'wb') as f:\n",
        "    f.write(result)"
      ],
      "metadata": {
        "id": "Gfy53jYYfBZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit abusive relationship comments inference"
      ],
      "metadata": {
        "id": "vn6sESd4f9H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_jsonl = f'{PATHS.save}/arc_inference.jsonl'\n",
        "make_inference_jsonl(PATHS.arc, inference_jsonl, CONFIG.model)"
      ],
      "metadata": {
        "id": "OcXuschxf9H5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = submit_batch(inference_jsonl)"
      ],
      "metadata": {
        "id": "Vj0qs-cLf9H6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = client.batches.retrieve(batch_job.id)\n",
        "print(batch_job)"
      ],
      "metadata": {
        "id": "vsOv5uruf9H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_file_id = batch_job.output_file_id\n",
        "result = client.files.content(result_file_id).content\n",
        "arc_predicted_jsonl = f'{PATHS.save}/arc_predicted.jsonl'\n",
        "with open(arc_predicted_jsonl, 'wb') as f:\n",
        "    f.write(result)"
      ],
      "metadata": {
        "id": "DLc5Qfn0f9H8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit toxic inference"
      ],
      "metadata": {
        "id": "42W_NjbqIAvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_jsonl = f'{PATHS.save}/toxic_inference.jsonl'\n",
        "make_inference_jsonl(PATHS.toxic, inference_jsonl, CONFIG.model)"
      ],
      "metadata": {
        "id": "TBHS0qnXIABo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = submit_batch(inference_jsonl)"
      ],
      "metadata": {
        "id": "WP3lhxuQIRNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_job = client.batches.retrieve(batch_job.id)\n",
        "print(batch_job)"
      ],
      "metadata": {
        "id": "WufZRU7gIRNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_file_id = batch_job.output_file_id\n",
        "\n",
        "result = client.files.content(result_file_id).content\n",
        "toxic_predicted_jsonl = f'{PATHS.save}/toxic_predicted.jsonl'\n",
        "with open(toxic_predicted_jsonl, 'wb') as f:\n",
        "    f.write(result)"
      ],
      "metadata": {
        "id": "8Ky3UBoUIRNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Inference Result"
      ],
      "metadata": {
        "id": "DpXTHtyYM6mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_df(jsonl):\n",
        "    with open(jsonl) as f:\n",
        "        json_lines = f.readlines()\n",
        "        json_objs = [json.loads(line) for line in json_lines]\n",
        "    df = pd.DataFrame(columns=(['id']+labels))\n",
        "    for i, json_obj in enumerate(json_objs):\n",
        "        json_content = json.loads(json_obj['response']['body']['choices'][0]['message']['content'])\n",
        "        s = pd.Series(data=json_content)\n",
        "        df.loc[i] = s\n",
        "    for label in labels:\n",
        "        df[label] = df[label].astype('int')\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZxjnSvTvMsgh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label suicide watch data"
      ],
      "metadata": {
        "id": "p-6zjnjoeDoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw_predicted_df = get_df(sw_predicted_jsonl)\n",
        "sw_labeled_df = pd.merge(sw_df, sw_predicted_df, how='inner', on='id')\n",
        "sw_labeled_df.to_csv(f'{PATHS.save}/sw_v2_labeled.tsv', sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "TbgRg95fabSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label abusive relationship data"
      ],
      "metadata": {
        "id": "dE5mVmdZeWY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ar_predicted_df = get_df(ar_predicted_jsonl)\n",
        "ar_labeled_df = pd.merge(ar_df, ar_predicted_df, how='inner', on='id')\n",
        "ar_labeled_df.to_csv(f'{PATHS.save}/ar_v2_labeled.tsv', sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "FvWKK9v_eZax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label abusive relationship comments data"
      ],
      "metadata": {
        "id": "4blDC-faidOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arc_predicted_df = get_df(arc_predicted_jsonl)\n",
        "arc_labeled_df = pd.merge(arc_df, arc_predicted_df, how='inner', on='id')\n",
        "arc_labeled_df.to_csv(f'{PATHS.save}/arc_v2_labeled.tsv', sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "C99CXQM8idOV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label toxic data"
      ],
      "metadata": {
        "id": "begvaYMYnbpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_predicted_df = get_df(toxic_predicted_jsonl)\n",
        "toxic_labeled_df = pd.merge(toxic_df, toxic_predicted_df, how='inner', on='id')\n",
        "toxic_labeled_df.to_csv(f'{PATHS.save}/toxic_v2_labeled.tsv', sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "zgZjVsa4nbpk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}